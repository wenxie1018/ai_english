import io
import json
import os
import re
import traceback 
import sys

from flask import Flask, request, jsonify
from flask_cors import CORS # type: ignore
from google.cloud import vision
from google.cloud import storage 
from dotenv import load_dotenv

import vertexai # type: ignore
from vertexai.generative_models import GenerativeModel, Part, Tool, grounding, HarmCategory, HarmBlockThreshold, ToolConfig # type: ignore

# --- åˆå§‹åŒ– Flask æ‡‰ç”¨ ---
app = Flask(__name__)
CORS(app) # é–‹ç™¼éšæ®µå…è¨±æ‰€æœ‰ä¾†æºï¼Œç”Ÿç”¢ç’°å¢ƒæ‡‰é…ç½®å…·é«”ä¾†æº

# åŠ è¼‰ç’°å¢ƒè®Šæ•¸
load_dotenv() 

# --- é…ç½® ---
GCP_PROJECT_ID = os.environ.get("GCP_PROJECT_ID")
GCP_LOCATION = os.environ.get("GCP_LOCATION", "global")
GEMINI_MODEL_NAME = os.environ.get("GEMINI_MODEL_NAME")

DATASTORE_ID = os.environ.get("DATASTORE_ID")
DATASTORE_COLLECTION_LOCATION = "global"
DATASTORE_RESOURCE_NAME = f"projects/{GCP_PROJECT_ID}/locations/{DATASTORE_COLLECTION_LOCATION}/collections/default_collection/dataStores/{DATASTORE_ID}"

# GCS Bucket ç”¨æ–¼å­˜å„² Prompt æ–‡ä»¶
GCS_PROMPT_BUCKET_NAME = os.environ.get("GCS_PROMPT_BUCKET_NAME")

# --- åˆå§‹åŒ– Google Cloud å®¢æˆ¶ç«¯ ---
try:
    vertexai.init(project=GCP_PROJECT_ID, location=GCP_LOCATION)
    vision_client = vision.ImageAnnotatorClient()
    storage_client = storage.Client(project=GCP_PROJECT_ID)

    gemini_model = GenerativeModel(GEMINI_MODEL_NAME)
    search_tool = Tool.from_retrieval(
        grounding.Retrieval(grounding.VertexAISearch(datastore=DATASTORE_RESOURCE_NAME))
    )
    tools_list = [search_tool]
    print("Vertex AI and Google Cloud clients initialized successfully.")

except Exception as e:
    print(f"Error initializing Google Cloud clients: {e}")
    traceback.print_exc()

# --- è¼”åŠ©å‡½æ•¸ ---
def get_size(obj):
    """éæ­¸è¨ˆç®—ç‰©ä»¶åœ¨è¨˜æ†¶é«”ä¸­çš„å¤§å°ï¼ˆä»¥MBç‚ºå–®ä½ï¼‰ã€‚"""
    seen_ids = set()
    
    def sizeof_detail(o):
        if id(o) in seen_ids:
            return 0
        seen_ids.add(id(o))
        size = sys.getsizeof(o)
        if isinstance(o, dict):
            size += sum(sizeof_detail(v) for v in o.values())
            size += sum(sizeof_detail(k) for k in o.keys())
        elif hasattr(o, '__dict__'):
            size += sizeof_detail(o.__dict__)
        elif hasattr(o, '__iter__') and not isinstance(o, (str, bytes, bytearray)):
            size += sum(sizeof_detail(i) for i in o)
        return size

    return sizeof_detail(obj) / (1024 * 1024)

def process_and_compress_image(file_bytes, max_size_mb=20, max_dimension=1200, quality=85):
    """
    æª¢æŸ¥ã€å£“ç¸®ä¸¦èª¿æ•´åœ–ç‰‡å¤§å°ã€‚
    è¿”å›å£“ç¸®å¾Œçš„åœ–ç‰‡äºŒé€²åˆ¶æ•¸æ“šï¼Œå¦‚æœæª”æ¡ˆéå¤§æˆ–éåœ–ç‰‡å‰‡è¿”å› Noneã€‚
    """
    file_size_mb = len(file_bytes) / (1024 * 1024)
    if file_size_mb > max_size_mb:
        print(f"ERROR: File is too large ({file_size_mb:.2f}MB), limit is {max_size_mb}MB.")
        return None
        
    try:
        img = Image.open(io.BytesIO(file_bytes))
        
        # è½‰æ›ç‚º RGB ä»¥é¿å…è™•ç† RGBA æˆ– P æ¨¡å¼æ™‚çš„å„²å­˜å•é¡Œ
        if img.mode not in ('RGB', 'L'): # L for grayscale
            img = img.convert('RGB')
            
        img.thumbnail((max_dimension, max_dimension))
        
        output_buffer = io.BytesIO()
        img.format = 'JPEG' # å¼·åˆ¶å­˜ç‚º JPEG ä»¥ç¢ºä¿å£“ç¸®
        img.save(output_buffer, format='JPEG', quality=quality)
        compressed_bytes = output_buffer.getvalue()
        
        compressed_size_mb = len(compressed_bytes) / (1024 * 1024)
        print(f"Image compressed from {file_size_mb:.2f}MB to {compressed_size_mb:.2f}MB.")
        return compressed_bytes
    except Exception as e:
        print(f"ERROR: Could not process or compress image. It might not be a valid image file. Error: {e}")
        return None
    
def perform_ocr(image_file_storage): # <--- æ¢å¾© perform_ocr å‡½æ•¸
    """ä½¿ç”¨ Google Cloud Vision API å°åœ–ç‰‡æ–‡ä»¶åŸ·è¡Œ OCRã€‚"""
    if not image_file_storage:
        return "OCR_ERROR: No image file provided."
    try:
        print(f"Performing OCR on image: {image_file_storage.filename}")
        content = image_file_storage.read()
        image = vision.Image(content=content)
        response = vision_client.text_detection(image=image)
        if response.error.message:
            raise Exception(f"Vision API error: {response.error.message}")
        return response.text_annotations[0].description if response.text_annotations else ""
    except Exception as e:
        print(f"Error during OCR: {e}")
        traceback.print_exc()
        return f"OCR_ERROR: {str(e)}"


def get_prompt_from_gcs(bucket_name, file_path_in_bucket):
    """å¾ GCS è®€å– Prompt æ–‡æœ¬ã€‚"""
    try:
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(file_path_in_bucket)
        print(f"bucket_name:{bucket_name},file_path_in_bucket:{file_path_in_bucket}")
        if not blob.exists():
            print(f"Error: Prompt file gs://{bucket_name}/{file_path_in_bucket} not found.")
            return None
        prompt_text = blob.download_as_text()
        print(f"Successfully loaded prompt from gs://{bucket_name}/{file_path_in_bucket}")
        return prompt_text
    except Exception as e:
        print(f"Error fetching prompt from GCS (gs://{bucket_name}/{file_path_in_bucket}): {e}")
        traceback.print_exc()
        return None
    
def get_standard_answer_for_lesson_from_gcs(bucket_name, base_file_path, grade_level, learnsheets_key, worksheet_category):
    """
    å¾ GCS è®€å–æŒ‡å®šå¹´ç´šå’Œå­¸ç¿’å–®ä¸»é¡Œçš„å®Œæ•´æ¨™æº–ç­”æ¡ˆ JSONï¼Œ
    ä¸¦æå–è©²ä¸»é¡Œ (Lesson X) çš„æ•¸æ“šã€‚
    
    Args:
        bucket_name (str): GCS å­˜å„²æ¡¶åç¨±ã€‚
        base_file_path (str): åŸºç¤æª”æ¡ˆè·¯å¾‘ï¼Œä¾‹å¦‚ 'ai_english_tutor/ai_english_file/'ã€‚
        grade_level (str): å¹´ç´šï¼Œä¾‹å¦‚ 'ä¸ƒå¹´ç´š'ã€‚
        learnsheets_key (str): å­¸ç¿’å–®ä¸»é¡Œï¼Œä¾‹å¦‚ 'Lesson 1'ã€‚
        
    Returns:
        dict: è©² Lesson çš„æ¨™æº–ç­”æ¡ˆæ•¸æ“šå­—å…¸ï¼Œå¦‚æœæ‰¾ä¸åˆ°å‰‡è¿”å› Noneã€‚
    """
    answer_file_map = {
        "ä¸ƒå¹´ç´šå…¨è‹±æå•å­¸ç¿’å–®åƒè€ƒç­”æ¡ˆ":"å…¨è‹±æå•å­¸ç¿’å–®åƒè€ƒç­”æ¡ˆ(01_1ä¸‹).txt",
        "å…«å¹´ç´šå…¨è‹±æå•å­¸ç¿’å–®åƒè€ƒç­”æ¡ˆ":"å…¨è‹±æå•å­¸ç¿’å–®åƒè€ƒç­”æ¡ˆ(01_2ä¸‹).txt",
        "ä¹å¹´ç´šå…¨è‹±æå•å­¸ç¿’å–®åƒè€ƒç­”æ¡ˆ":"å…¨è‹±æå•å­¸ç¿’å–®åƒè€ƒç­”æ¡ˆ(01_3ä¸‹).txt",
        "ä¸ƒå¹´ç´šå·®ç•°åŒ–å­¸ç¿’å–®åƒè€ƒç­”æ¡ˆ":"å·®ç•°åŒ–å­¸ç¿’å–®åƒè€ƒç­”æ¡ˆ(01_1ä¸‹).txt",
        "å…«å¹´ç´šå·®ç•°åŒ–å­¸ç¿’å–®åƒè€ƒç­”æ¡ˆ":"å·®ç•°åŒ–å­¸ç¿’å–®åƒè€ƒç­”æ¡ˆ(01_2ä¸‹).txt",
        "ä¹å¹´ç´šå·®ç•°åŒ–å­¸ç¿’å–®åƒè€ƒç­”æ¡ˆ":"å·®ç•°åŒ–å­¸ç¿’å–®åƒè€ƒç­”æ¡ˆ(01_3ä¸‹).txt",
    }

    # æ ¹æ“š grade_level å’Œ worksheet_category æ‰¾åˆ°å°æ‡‰çš„æª”æ¡ˆ
    full_file_key = f"{grade_level}{worksheet_category}"
    target_filename = answer_file_map.get(full_file_key)
    
    if not target_filename:
        print(f"Error: No standard answer file found for grade '{grade_level}' and category '{worksheet_category}'.")
        return None
    
    try:
        bucket = storage_client.bucket(bucket_name)
        base_file_path = f"{base_file_path}{target_filename}"
        blob = bucket.blob(base_file_path)
        print(f"base_file_path:{base_file_path},target_filename:{target_filename},bucket_name:{bucket_name},blob:{blob}")
        if not blob.exists():
            print(f"Error: Standard answer file gs://{bucket_name}{base_file_path} not found.")
            return None
        
        json_content = blob.download_as_text()
        all_answers_data = json.loads(json_content)
        
        # æå–æŒ‡å®š learnsheets_key (ä¾‹å¦‚ "Lesson 1") çš„æ•¸æ“š
        lesson_data = all_answers_data.get(learnsheets_key)
        
        if not lesson_data:
            print(f"Warning: '{learnsheets_key}' not found in standard answer file {target_filename}.")
            return None
            
        print(f"Successfully loaded standard answers for {learnsheets_key} from gs://{bucket_name}/{target_filename}")
        return lesson_data
    
    except Exception as e:
        print(f"Error fetching standard answers from GCS (gs://{bucket_name}/{target_filename}): {e}")
        traceback.print_exc()
        return None
    
def get_standard_answer_for_reading_writing_from_gcs(bucket_name, base_file_path, grade_level, bookrange):
    """
    å¾ GCS è®€å–æŒ‡å®šå¹´ç´šå’Œå†Šæ¬¡çš„è®€å¯«ç¿’ä½œæ¨™æº–ç­”æ¡ˆ JSONï¼Œ
    ä¸¦æå–è©²å†Šæ¬¡ (ä¾‹å¦‚ Book 5) çš„æ•¸æ“šã€‚
    
    Args:
        bucket_name (str): GCS å­˜å„²æ¡¶åç¨±ã€‚
        base_file_path (str): åŸºç¤æª”æ¡ˆè·¯å¾‘ï¼Œä¾‹å¦‚ 'ai_english_tutor/ai_english_file/'ã€‚
        grade_level (str): å¹´ç´šï¼Œä¾‹å¦‚ 'ä¸ƒå¹´ç´š'ã€‚
        bookrange (str): å†Šæ¬¡ä¸»é¡Œï¼Œä¾‹å¦‚ 'Book 5'ã€‚
        
    Returns:
        dict: è©²å†Šæ¬¡çš„æ¨™æº–ç­”æ¡ˆæ•¸æ“šå­—å…¸ï¼Œå¦‚æœæ‰¾ä¸åˆ°å‰‡è¿”å› Noneã€‚
    """
    # å‡è¨­è®€å¯«ç¿’ä½œçš„ç­”æ¡ˆæª”åæ ¼å¼
    answer_file_map = {
        "ä¸ƒå¹´ç´šè®€å¯«ç¿’ä½œåƒè€ƒç­”æ¡ˆ": "113_1ç¿’ä½œæ¨™æº–ç­”æ¡ˆ.txt", 
        "å…«å¹´ç´šè®€å¯«ç¿’ä½œåƒè€ƒç­”æ¡ˆ": "113_2ç¿’ä½œæ¨™æº–ç­”æ¡ˆ.txt", 
        "ä¹å¹´ç´šè®€å¯«ç¿’ä½œåƒè€ƒç­”æ¡ˆ": "113_3ç¿’ä½œæ¨™æº–ç­”æ¡ˆ.txt", 
    }

    # æ ¹æ“š grade_level æ‰¾åˆ°å°æ‡‰çš„æª”æ¡ˆ
    full_file_key = f"{grade_level}è®€å¯«ç¿’ä½œåƒè€ƒç­”æ¡ˆ"
    target_filename = answer_file_map.get(full_file_key)
    
    if not target_filename:
        print(f"Error: No standard answer file found for reading/writing grade '{grade_level}'.")
        return None
    
    try:
        bucket = storage_client.bucket(bucket_name)
        full_file_path = f"{base_file_path}{target_filename}"
        blob = bucket.blob(full_file_path)
        print(f"Attempting to load reading/writing answers from: gs://{bucket_name}/{full_file_path}")

        if not blob.exists():
            print(f"Error: Standard answer file gs://{bucket_name}/{full_file_path} not found.")
            return None
        
        json_content = blob.download_as_text()
        all_answers_data = json.loads(json_content)
        
        # æå–æŒ‡å®š bookrange_key (ä¾‹å¦‚ "Book 5") çš„æ•¸æ“š
        book_data = all_answers_data.get(bookrange)
        
        if not book_data:
            print(f"Warning: '{bookrange}' not found in standard answer file {target_filename}.")
            return None
            
        print(f"Successfully loaded standard answers for {bookrange} from gs://{bucket_name}/{target_filename}")
        return book_data
    
    except Exception as e:
        print(f"Error fetching reading/writing standard answers from GCS (gs://{bucket_name}/{target_filename}): {e}")
        traceback.print_exc()
        return None

def get_json_format_example(submission_type, mock_paragraph, mock_quiz, mock_learning_sheet, mock_reading_writing):
    """æ ¹æ“šæäº¤é¡å‹è¿”å›å°æ‡‰çš„ JSON æ ¼å¼ç¯„ä¾‹å­—ç¬¦ä¸²ã€‚"""
    # é€™è£¡æˆ‘å€‘ä»ç„¶ä½¿ç”¨ mock data ä¾†å®šç¾© JSON çµæ§‹ç¯„ä¾‹
    # æ‚¨ä¹Ÿå¯ä»¥å°‡é€™äº› JSON çµæ§‹ç¯„ä¾‹å­˜å„²ç‚º GCS æ–‡ä»¶æˆ–å…¶ä»–é…ç½®
    if submission_type == 'æ¸¬é©—å¯«ä½œè©•æ”¹':
        return json.dumps(mock_quiz, ensure_ascii=False, indent=2)
    elif submission_type == 'æ®µè½å¯«ä½œè©•é–±':
        return json.dumps(mock_paragraph, ensure_ascii=False, indent=2)
    elif submission_type == 'å­¸ç¿’å–®æ‰¹æ”¹':
        return json.dumps(mock_learning_sheet, ensure_ascii=False, indent=2)
    elif submission_type == 'è®€å¯«ç¿’ä½œè©•åˆ†':
        return json.dumps(mock_reading_writing, ensure_ascii=False, indent=2)
    else:
        print(f"Warning: Unknown submission_type '{submission_type}' for JSON example. Defaulting to paragraph.")
        return json.dumps(mock_paragraph, ensure_ascii=False, indent=2) # é»˜èª

# --- ä¸»è¦è·¯ç”± ---
@app.route('/api/grade', methods=['POST'])
def grade_writing():
    print(f"\n--- New request to /api/grade ---")
    print(f"Request Content-Type: {request.content_type}")

    try:
        submission_type = None
        grade_level = None
        text_input = None
        bookrange = None
        learnsheets = None
        worksheet_category = None
        essay_image_files = []
        learning_sheet_files = []
        reading_writing_files = []
        standard_answer_text = None
        standard_answer_image_files = []
        scoring_instructions = None

        if request.content_type and 'multipart/form-data' in request.content_type.lower():
            print("Processing as multipart/form-data")
            submission_type = request.form.get('submissionType')
            grade_level = request.form.get('gradeLevel')
            text_input = request.form.get('text')
            if submission_type == 'è®€å¯«ç¿’ä½œè©•åˆ†':
                bookrange = request.form.get('bookrange')
                print(f"Extracted bookrange from form: {bookrange}")
            if submission_type == 'å­¸ç¿’å–®æ‰¹æ”¹':
                learnsheets = request.form.get('learnsheets')
                worksheet_category = request.form.get('worksheetCategory')
                print(f"Extracted learnsheets from form: {learnsheets},Category: {worksheet_category}")
            essay_image_files = request.files.getlist('essayImage')
            learning_sheet_files = request.files.getlist('learningSheetFile')
            reading_writing_files = request.files.getlist('readingWritingFile')
            if submission_type == 'æ¸¬é©—å¯«ä½œè©•æ”¹':
                standard_answer_text = request.form.get('standardAnswerText', '')
                standard_answer_image_files = request.files.getlist('standardAnswerImage') # get è¿”å› None å¦‚æœä¸å­˜åœ¨
                scoring_instructions = request.form.get('scoringInstructions', '')
        elif request.is_json:
            print("Processing as JSON")
            data = request.get_json()
            submission_type = data.get('submissionType')
            grade_level = data.get('gradeLevel')
            bookrange = data.get('bookrange')
            learnsheets = data.get('learnsheets')
            worksheet_category = data.get('worksheetCategory')
            text_input = data.get('text') 
            if submission_type == 'æ¸¬é©—å¯«ä½œè©•æ”¹':
                standard_answer_text = data.get('standardAnswerText', '')
                scoring_instructions = data.get('scoringInstructions', '')
        else:
            print(f"Warning: Received request with unhandled Content-Type: {request.content_type}")
            submission_type = request.form.get('submissionType')
            grade_level = request.form.get('gradeLevel')


        print(f"Parsed Submission Type: {submission_type}, Grade Level: {grade_level}")

        # --- å¾ŒçºŒçš„é©—è­‰å’Œè™•ç†é‚è¼¯ ---
        if not submission_type or not grade_level: # ç¾åœ¨é€™å€‹åˆ¤æ–·æ›´é—œéµ
            return jsonify({"error": "Missing submissionType or gradeLevel after parsing request"}), 400

        # --- æº–å‚™å‚³éçµ¦ Gemini çš„å…§å®¹åˆ—è¡¨ ---
        # Gemini çš„ generate_content å¯ä»¥æ¥å—ä¸€å€‹ Part ç‰©ä»¶åˆ—è¡¨ (æ–‡æœ¬å’Œåœ–ç‰‡)
        contents_for_gemini = []

        essay_content = "" # å„²å­˜çµ¦ Prompt å­—ç¬¦ä¸²çš„å…§å®¹ (å¯ä»¥æ˜¯æ–‡æœ¬æˆ–æŒ‡ç¤ºæ€§æ–‡æœ¬)
        
        # è™•ç†å­¸ç”Ÿä½œæ¥­å…§å®¹ï¼šå„ªå…ˆæ–‡æœ¬è¼¸å…¥ï¼Œå…¶æ¬¡åœ–ç‰‡æ–‡ä»¶
        if submission_type == 'æ®µè½å¯«ä½œè©•é–±' or submission_type == 'æ¸¬é©—å¯«ä½œè©•æ”¹':
            if text_input:
                essay_content = text_input
            elif essay_image_files:
                # ä½¿ç”¨ Vision API åŸ·è¡Œ OCRï¼Œçµæœç”¨æ–¼å¡«å…¥ Prompt ä¸­çš„ {essay_content}
                ocr_results = []
                contents_for_gemini.append(Part.from_text("å­¸ç”Ÿæäº¤çš„åŸå§‹ä½œæ¥­åœ–ç‰‡å…§å®¹ï¼Œä¾›æ‚¨åƒè€ƒç†è§£å…¶ç‰ˆé¢å’Œæ‰‹å¯«å…§å®¹ï¼š"))
                for file_storage in essay_image_files:
                    file_storage.seek(0) # é‡ç½®æ–‡ä»¶æŒ‡é‡ï¼Œç¢ºä¿ OCR å’Œåœ–ç‰‡ Part éƒ½èƒ½è®€å–åˆ°å®Œæ•´å…§å®¹
                    ocr_text = perform_ocr(file_storage)
                    if "OCR_ERROR:" in ocr_text:
                        print(f"OCR failed for {file_storage.filename}: {ocr_text}. Skipping this file for OCR content.")
                        # å³ä½¿ OCR å¤±æ•—ï¼Œæˆ‘å€‘ä»å˜—è©¦å°‡åŸå§‹åœ–ç‰‡ä½œç‚º Part å‚³é
                        # é€™è£¡å¯ä»¥é¸æ“‡å ±éŒ¯æˆ–ç¹¼çºŒ
                    elif ocr_text.strip():
                        ocr_results.append(ocr_text)
                    
                    # å°‡åŸå§‹åœ–ç‰‡æ·»åŠ åˆ° Gemini çš„ Part åˆ—è¡¨ä¸­
                    file_storage.seek(0) # å†æ¬¡é‡ç½®æŒ‡é‡ï¼Œç¢ºä¿è®€å–å®Œæ•´çš„åœ–ç‰‡æ•¸æ“š
                    try:
                        image_data = file_storage.read()
                        contents_for_gemini.append(Part.from_data(data=image_data, mime_type=file_storage.content_type))
                        print(f"Added student essay image {file_storage.filename} as Part.")
                    except Exception as e:
                        print(f"Error reading student essay image {file_storage.filename} for Gemini: {e}")
                        traceback.print_exc()
                        return jsonify({"error": f"Failed to read student essay image file {file_storage.filename} for Gemini: {str(e)}"}), 400

                if not ocr_results and not text_input: # å¦‚æœæ‰€æœ‰ OCR éƒ½å¤±æ•—æˆ–æ²’æœ‰ç´”æ–‡æœ¬
                    return jsonify({"error": "OCR failed or returned empty for all provided images, and no text input."}), 400
                
                essay_content = "\n\n".join(ocr_results) if ocr_results else "ï¼ˆåœ–ç‰‡å…§å®¹ OCR å¤±æ•—æˆ–ç‚ºç©ºï¼Œè«‹åƒè€ƒéš¨å¾Œæä¾›çš„åŸå§‹åœ–ç‰‡ï¼‰" # å³ä½¿ OCR å¤±æ•—ï¼Œä¹Ÿçµ¦å€‹æç¤º

            else:
                return jsonify({"error": f"For {submission_type}, text input or an essay image is required."}), 400
        elif submission_type == 'å­¸ç¿’å–®æ‰¹æ”¹':
            if learning_sheet_files:
                ocr_results = []
                contents_for_gemini.append(Part.from_text("å­¸ç”Ÿæäº¤çš„åŸå§‹å­¸ç¿’å–®åœ–ç‰‡å…§å®¹ï¼Œä¾›æ‚¨åƒè€ƒç†è§£å…¶ç‰ˆé¢å’Œæ‰‹å¯«å…§å®¹ï¼š"))
                for file_storage in learning_sheet_files:
                    file_storage.seek(0)
                    ocr_text = perform_ocr(file_storage)
                    if "OCR_ERROR:" in ocr_text:
                        print(f"OCR failed for {file_storage.filename}: {ocr_text}. Skipping this file for OCR content.")
                    elif ocr_text.strip():
                        ocr_results.append(ocr_text)

                    file_storage.seek(0)
                    try:
                        image_data = file_storage.read()
                        contents_for_gemini.append(Part.from_data(data=image_data, mime_type=file_storage.content_type))
                        print(f"Added learning sheet image {file_storage.filename} as Part.")
                    except Exception as e:
                        print(f"Error reading learning sheet image {file_storage.filename} for Gemini: {e}")
                        traceback.print_exc()
                        return jsonify({"error": f"Failed to read learning sheet file {file_storage.filename} for Gemini: {str(e)}"}), 400

                if not ocr_results:
                    return jsonify({"error": "OCR failed or returned empty for all provided learning sheet images."}), 400
                essay_content = "\n\n".join(ocr_results)
            else:
                return jsonify({"error": "Learning sheet file is required for 'å­¸ç¿’å–®æ‰¹æ”¹'."}), 400
        elif submission_type == 'è®€å¯«ç¿’ä½œè©•åˆ†':
            if reading_writing_files:
                ocr_results = []
                contents_for_gemini.append(Part.from_text("å­¸ç”Ÿæäº¤çš„åŸå§‹è®€å¯«ç¿’ä½œåœ–ç‰‡å…§å®¹ï¼Œä¾›æ‚¨åƒè€ƒç†è§£å…¶ç‰ˆé¢å’Œæ‰‹å¯«å…§å®¹ï¼š"))
                for file_storage in reading_writing_files:
                    file_storage.seek(0)
                    ocr_text = perform_ocr(file_storage)
                    if "OCR_ERROR:" in ocr_text:
                        print(f"OCR failed for {file_storage.filename}: {ocr_text}. Skipping this file for OCR content.")
                    elif ocr_text.strip():
                        ocr_results.append(ocr_text)

                    file_storage.seek(0)
                    try:
                        image_data = file_storage.read()
                        contents_for_gemini.append(Part.from_data(data=image_data, mime_type=file_storage.content_type))
                        print(f"Added reading/writing worksheet image {file_storage.filename} as Part.")
                    except Exception as e:
                        print(f"Error reading reading/writing worksheet image {file_storage.filename} for Gemini: {e}")
                        traceback.print_exc()
                        return jsonify({"error": f"Failed to read reading/writing worksheet file {file_storage.filename} for Gemini: {str(e)}"}), 400

                if not ocr_results:
                    return jsonify({"error": "OCR failed or returned empty for all provided reading/writing worksheet images."}), 400
                essay_content = "\n\n".join(ocr_results)
            else:
                return jsonify({"error": "Reading/writing worksheet file is required for 'è®€å¯«ç¿’ä½œè©•åˆ†'."}), 400
        else:
            return jsonify({"error": f"Unsupported submission type for content processing: {submission_type}"}), 400

        if not essay_content.strip() and not text_input and not contents_for_gemini: # ç¢ºä¿æœ‰ä»»ä½•å½¢å¼çš„å…§å®¹
            return jsonify({"error": "Essay content is empty after processing input"}), 400
        print(f"Essay content (first 100 chars): {essay_content[:100]}...")
        
        # è™•ç†æ¨™æº–ç­”æ¡ˆï¼ˆåƒ…æ¸¬é©—å¯«ä½œè©•æ”¹ï¼‰
        processed_standard_answer = ""
        if submission_type == 'æ¸¬é©—å¯«ä½œè©•æ”¹':
            if standard_answer_text:
                processed_standard_answer = standard_answer_text
            elif standard_answer_image_files:
                ocr_standard_answer_results = []
                contents_for_gemini.append(Part.from_text("\næ¸¬é©—çš„åŸå§‹æ¨™æº–ç­”æ¡ˆåœ–ç‰‡å…§å®¹ï¼Œä¾›æ‚¨åƒè€ƒç†è§£å…¶ç‰ˆé¢å’Œæ‰‹å¯«å…§å®¹ï¼š"))
                for file_storage in standard_answer_image_files:
                    file_storage.seek(0) # é‡ç½®æŒ‡é‡
                    ocr_text = perform_ocr(file_storage)
                    if "OCR_ERROR:" in ocr_text:
                        print(f"OCR for standard answer image {file_storage.filename} failed: {ocr_text}. Skipping OCR content for this file.")
                    elif ocr_text.strip():
                        ocr_standard_answer_results.append(ocr_text)
                    
                    file_storage.seek(0) # å†æ¬¡é‡ç½®æŒ‡é‡
                    try:
                        image_data = file_storage.read()
                        contents_for_gemini.append(Part.from_data(data=image_data, mime_type=file_storage.content_type))
                        print(f"Added standard answer image {file_storage.filename} as Part.")
                    except Exception as e:
                        print(f"Error reading standard answer image {file_storage.filename} for Gemini: {e}")
                        traceback.print_exc()
                        print(f"Failed to read standard answer image file {file_storage.filename} for Gemini: {str(e)}")

                if ocr_standard_answer_results:
                    processed_standard_answer = "\n\n".join(ocr_standard_answer_results)
                else:
                    processed_standard_answer = "ï¼ˆæ¨™æº–ç­”æ¡ˆåœ–ç‰‡å…§å®¹ OCR å¤±æ•—æˆ–ç‚ºç©ºï¼Œè«‹åƒè€ƒéš¨å¾Œæä¾›çš„åŸå§‹åœ–ç‰‡ï¼‰"
                    print("OCR for all standard answer images failed or returned empty.")
            print(f"Processed Standard Answer (first 100 chars): {processed_standard_answer[:100]}...")
        # --- æ–°å¢ï¼šè¼‰å…¥å­¸ç¿’å–®æ¨™æº–ç­”æ¡ˆçš„é‚è¼¯ ---
        standard_answers_json_str = "" 

        # é‚è¼¯ 1ï¼šè™•ç†ã€Œå­¸ç¿’å–®æ‰¹æ”¹ã€çš„æ¨™æº–ç­”æ¡ˆ
        if submission_type == 'å­¸ç¿’å–®æ‰¹æ”¹' and learnsheets and worksheet_category:
            print(f"Attempting to load standard answers for {grade_level} {worksheet_category} {learnsheets}")
            standard_answers_data = get_standard_answer_for_lesson_from_gcs(
                GCS_PROMPT_BUCKET_NAME,
                "ai_english_file/", # ä½ çš„ GCS æª”æ¡ˆè·¯å¾‘
                grade_level,
                learnsheets,
                worksheet_category
            )
            if standard_answers_data:
                standard_answers_json_str = json.dumps(standard_answers_data, ensure_ascii=False, indent=2)
                print(f"Loaded specific 'å­¸ç¿’å–®' standard answers (first 200 chars): {standard_answers_json_str[:200]}...")
            else:
                print("Failed to load specific 'å­¸ç¿’å–®' standard answers. Gemini will rely on search_tool for all answers.")
        
        # é‚è¼¯ 2ï¼šã€æ–°å¢ã€‘è™•ç†ã€Œè®€å¯«ç¿’ä½œè©•åˆ†ã€çš„æ¨™æº–ç­”æ¡ˆ
        elif submission_type == 'è®€å¯«ç¿’ä½œè©•åˆ†' and bookrange:
            print(f"Attempting to load standard answers for {grade_level} {bookrange}")
            standard_answers_data = get_standard_answer_for_reading_writing_from_gcs(
                GCS_PROMPT_BUCKET_NAME,
                "ai_english_file/", # ä½ çš„ GCS æª”æ¡ˆè·¯å¾‘
                grade_level,
                bookrange # ä½¿ç”¨ bookrange ä½œç‚º key
            )
            if standard_answers_data:
                standard_answers_json_str = json.dumps(standard_answers_data, ensure_ascii=False, indent=2)
                print(f"Loaded specific 'è®€å¯«ç¿’ä½œ' standard answers (first 200 chars): {standard_answers_json_str[:200]}...")
            else:
                print("Failed to load specific 'è®€å¯«ç¿’ä½œ' standard answers. Gemini will rely on search_tool for all answers.")


        # --- 1. æ ¹æ“š submissionType ç¢ºå®šè¦åŠ è¼‰çš„ Prompt æ–‡ä»¶å ---
        prompt_file_map = {
            "æ®µè½å¯«ä½œè©•é–±": "æ®µè½å¯«ä½œè©•é–±.txt",
            "æ¸¬é©—å¯«ä½œè©•æ”¹": "æ¸¬é©—å¯«ä½œè©•æ”¹.txt",
            "å­¸ç¿’å–®æ‰¹æ”¹": "å­¸ç¿’å–®æ‰¹æ”¹.txt",
            "è®€å¯«ç¿’ä½œè©•åˆ†": "è®€å¯«ç¿’ä½œè©•åˆ†.txt"
        }
        prompt_file_name = prompt_file_map.get(submission_type)
        if not prompt_file_name:
            return jsonify({"error": f"Unsupported submission type: {submission_type}"}), 400

        # --- 2. å¾ GCS åŠ è¼‰å°æ‡‰çš„ Prompt æ¨¡æ¿ ---
        prompt_folder_path = "ai_english_prompt/"
        full_prompt_path_in_bucket = f"{prompt_folder_path}{prompt_file_name}"

        base_prompt_text = get_prompt_from_gcs(GCS_PROMPT_BUCKET_NAME, full_prompt_path_in_bucket)
        if not base_prompt_text:
            return jsonify({"error": f"Failed to load prompt template for {submission_type} from gs://{GCS_PROMPT_BUCKET_NAME}/{full_prompt_path_in_bucket}"}), 500

        # --- 3. æº–å‚™ JSON æ ¼å¼ç¯„ä¾‹ (å¾ mock data ç”Ÿæˆ) ---
        # ç‚ºäº†æ¼”ç¤ºï¼Œæˆ‘å€‘é‚„æ˜¯éœ€è¦ mock data ä¾†å®šç¾© JSON çµæ§‹
        # æ‚¨ä¹‹å¾Œå¯ä»¥æ ¹æ“šéœ€è¦èª¿æ•´é€™äº› mock data
        mock_paragraph_data_for_structure = {
        "submissionType": "æ®µè½å¯«ä½œè©•é–±",
        "error_analysis": [
            {
            "original_sentence": "With my heart beating rapidly in excitement, I tried to look past the sea olf people and see through the large glass windows of the department store.",
            "error_type": "æ‹¼å¯«éŒ¯èª¤",
            "error_content": "oIf æ‡‰ç‚º ofï¼Œdepartiment æ‡‰ç‚º department",
            "suggestion": "With my heart beating rapidly in excitement, I tried to look past the sea of people and see through the large glass windows of the department store. (olf æ‡‰ç‚º of, department store é€šå¸¸æ˜¯ä¸€å€‹è©çµ„ï¼Œä½†æ­¤è™• department å–®ç¨å‡ºç¾å¯èƒ½æŒ‡éƒ¨é–€ï¼Œå¦‚æœæŒ‡ç™¾è²¨å…¬å¸å‰‡æ‡‰ç‚º department store)"
            },
            {
            "original_sentence": "Every person waiting outside had the same goal as mine to take advantage of the huge sales the shop was offering.",
            "error_type": "æ–‡æ³•éŒ¯èª¤ (æ¯”è¼ƒçµæ§‹)",
            "error_content": "mine å¾Œé¢æ‡‰åŠ ä¸Š is æˆ– wasï¼Œä»¥å®Œæˆæ¯”è¼ƒã€‚",
            "suggestion": "Every person waiting outside had the same goal as mine: to take advantage of the huge sales the shop was offering. (åœ¨ mine å¾Œé¢åŠ ä¸Šå†’è™Ÿæˆ– is/was ä¾†å®Œæˆæ¯”è¼ƒçµæ§‹æœƒæ›´æ¸…æ™°)"
            },
            {
            "original_sentence": "However, many other customers had beaten me to the task.",
            "error_type": "ç”¨å­—é£è© (è¡¨é”ä¸è‡ªç„¶)",
            "error_content": "beaten me to the task ç•¥é¡¯ä¸è‡ªç„¶ï¼Œå¯æ›¿æ›ç‚ºæ›´å¸¸è¦‹çš„è¡¨é”æ–¹å¼ã€‚",
            "suggestion": "However, many other customers had arrived earlier / gotten there before me. ('beaten me to the task' ç•¥é¡¯ä¸è‡ªç„¶ï¼Œå¯æ›¿æ›ç‚ºæ›´å¸¸è¦‹çš„è¡¨é”æ–¹å¼)"
            },
            {
            "original_sentence": "Therefore, I stood slightly farther away from the enterance than I had planned,but that did not put out my ambition to purchase as many items as possible.",
            "error_type": "æ‹¼å¯«éŒ¯èª¤ï¼Œæ¨™é»ç¬¦è™Ÿ",
            "error_content": "enterance æ‡‰ç‚º entranceï¼Œbut å‰é¢çš„é€—è™Ÿæ‡‰æ”¹ç‚ºåˆ†è™Ÿæˆ–å¥è™Ÿ",
            "suggestion": "Therefore, I stood slightly farther away from the entrance than I had planned; but that did not diminish my ambition to purchase as many items as possible."
            },
            {
            "original_sentence": "The constant chatter around me became impatient as time trickled by.",
            "error_type": "ç”¨å­—é£è©",
            "error_content": "chatter æœ¬èº«ä¸æœƒæ„Ÿåˆ° impatientï¼Œæ‡‰æ˜¯äººæ„Ÿåˆ° impatientã€‚",
            "suggestion": "I became impatient with the constant chatter around me as time trickled by."
            }
        ],
        "rubric_evaluation": {
            "structure_performance": [
            {
                "item": "Task Fulfillment and Purpose",
                "score": 8,
                "comment": "å¾ˆå¥½åœ°å®Œæˆäº†ä»»å‹™ï¼Œæè¿°äº†ä¸€æ¬¡è³¼ç‰©çš„ç¶“æ­·ï¼Œä¸¦è¡¨é”äº†æƒ…æ„Ÿçš„è½‰è®Šã€‚ä¸»é¡Œæ˜ç¢ºã€‚"
            },
            {
                "item": "Topic Sentence and Main Idea",
                "score": 7,
                "comment": "æ®µè½ä¸­æœ‰å¤šå€‹ä¸»é¡Œå¥ï¼Œä½†ä¸»æ—¨æ˜ç¢ºï¼Œåœç¹è‘—è³¼ç‰©ç¶“æ­·å’Œæƒ…æ„Ÿè½‰è®Šå±•é–‹ã€‚"
            },
            {
                "item": "Supporting Sentences and Argument Development",
                "score": 7,
                "comment": "ç´°ç¯€æè¿°è±å¯Œï¼Œä½†éƒ¨åˆ†ç´°ç¯€å¯ä»¥æ›´ç²¾ç…‰ï¼Œä½¿è«–è¿°æ›´é›†ä¸­ã€‚"
            },
            {
                "item": "Cohesion and Coherence",
                "score": 7,
                "comment": "æ•´é«”é€£è²«æ€§ä¸éŒ¯ï¼Œä½†éƒ¨åˆ†å¥å­ä¹‹é–“çš„éŠœæ¥å¯ä»¥æ›´è‡ªç„¶ã€‚"
            },
            {
                "item": "Concluding Sentence and Closure",
                "score": 8,
                "comment": "çµå°¾ç¸½çµäº†æ•´ä»¶äº‹æƒ…ï¼Œä¸¦é»æ˜äº†ä¸»é¡Œï¼Œæœ‰å¾ˆå¥½çš„æ”¶å°¾ã€‚"
            }
            ],
            "content_language": [
            {
                "item": "Depth of Analysis and Critical Thinking",
                "score": 7,
                "comment": "å°æƒ…æ„Ÿçš„è½‰è®Šæœ‰ä¸€å®šç¨‹åº¦çš„åˆ†æï¼Œä½†å¯ä»¥æ›´æ·±å…¥åœ°æŒ–æ˜å…§å¿ƒæ„Ÿå—ã€‚"
            },
            {
                "item": "Grammar and Sentence Structure",
                "score": 6,
                "comment": "æ–‡æ³•åŸºç¤å°šå¯ï¼Œä½†å­˜åœ¨ä¸€äº›éŒ¯èª¤ï¼Œéœ€è¦åŠ å¼·ç·´ç¿’ã€‚"
            },
            {
                "item": "Vocabulary and Word Choice",
                "score": 7,
                "comment": "è©å½™ä½¿ç”¨æ°ç•¶ï¼Œä½†å¯ä»¥å˜—è©¦ä½¿ç”¨æ›´å¤šæ¨£åŒ–çš„è©å½™ã€‚"
            },
            {
                "item": "Spelling, Punctuation, and Mechanics",
                "score": 6,
                "comment": "æ‹¼å¯«å’Œæ¨™é»ç¬¦è™Ÿæ–¹é¢å­˜åœ¨ä¸€äº›éŒ¯èª¤ï¼Œéœ€è¦ä»”ç´°æª¢æŸ¥ã€‚"
            },
            {
                "item": "Persuasive Effectiveness and Audience Awareness",
                "score": 7,
                "comment": "æ•…äº‹å…·æœ‰ä¸€å®šçš„æ„ŸæŸ“åŠ›ï¼Œèƒ½å¼•èµ·è®€è€…çš„å…±é³´ã€‚"
            }
            ]
        },
        "overall_assessment": {
            "total_score": "68/100",
            "suggested_grade": "C+",
            "grade_basis": "ä¾æ“šä¸ƒå¹´ç´šæ¨™æº–è©•é‡ã€‚",
            "general_comment": "æ•´é«”è€Œè¨€ï¼Œä½œæ–‡å…§å®¹ç”Ÿå‹•æœ‰è¶£ï¼Œä½†æ–‡æ³•å’Œæ‹¼å¯«æ–¹é¢ä»éœ€åŠ å¼·ã€‚ç¹¼çºŒåŠªåŠ›ï¼Œæ³¨æ„ç´°ç¯€ï¼Œç›¸ä¿¡ä½ æœƒå¯«å¾—æ›´å¥½ï¼"
        },
        "model_paragraph": "With my heart beating rapidly in excitement, I tried to look past the sea of people and see through the large glass windows of the department store. Every person waiting outside had the same goal as mine: to take advantage of the huge sales the shop was offering. I had arrived early in the morning, hoping to be close to the doors. However, many other customers had arrived even earlier. Therefore, I stood slightly farther away from the entrance than I had planned, but that did not diminish my ambition to purchase as many items as possible. I became impatient with the constant chatter around me as time trickled by. Suddenly, the glass doors burst open. I watched as men and women in front of me flooded into the store. All around me, people pushed each other, eager to get in. We were like sardines in a box as we crammed through the narrow doors. Being too preoccupied to notice my surroundings, I tripped on the edge of the carpet. To my disappointment, I found myself sprawled on the floor, watching as people grabbed goods off the shelves. My ankle was sprained, and it was as though all my waiting had gone to waste. Even worse, no one even stopped to help me up. Limping around the store, I realized I couldn't get to the discounted items fast enough. Although I had arrived earlier than most, my carelessness had resulted in a disadvantage. I saw a number of products snatched up by quicker hands, and people watched as other people filled up carts and baskets. Consequently, my former excitement faded away, replaced by regret. How I wish I had not come! Having given up hope, I slowly made my way to the exit, my hands empty and my wallet full. Stepping out the glass doors, I noticed in the corner of my eye several people holding out signs. Curious, I went to check it out. It was a charity for stray dogs and they had brought puppies with them. I couldn't resist the urge to caress the canines' heads. Wagging their tails enthusiastically, they licked my palms. I giggled, all my disappointment dissolved like salt in water. After playing with them for a while, I pulled out my purse and donated all the money I had planned to spend. At the end of the day, I did go home with my purse empty. However, instead of products, I had a cute puppy in my hands. What a wonderful day it had been.",
        "teacher_summary_feedback": "ä½ çš„ä½œæ–‡å…§å®¹å¾ˆæœ‰è¶£ï¼Œæè¿°äº†ä¸€æ¬¡é›£å¿˜çš„è³¼ç‰©ç¶“æ­·ã€‚æ•…äº‹çš„æ•˜è¿°æµæš¢ï¼Œæƒ…æ„Ÿè¡¨é”ä¹Ÿæ¯”è¼ƒè‡ªç„¶ã€‚ä¸éï¼Œåœ¨æ–‡æ³•å’Œæ‹¼å¯«æ–¹é¢é‚„æœ‰é€²æ­¥çš„ç©ºé–“ã€‚å¤šåŠ ç·´ç¿’ï¼Œæ³¨æ„ç´°ç¯€ï¼Œç›¸ä¿¡ä½ æœƒå¯«å¾—æ›´å¥½ï¼"
        }
        mock_quiz_data_for_structure = {
        "submissionType": "æ¸¬é©—å¯«ä½œè©•æ”¹",
        "error_analysis_table": [
            {
            "original_sentence": "It was the anniversary of the mall where a mutitude of discounts took place.",
            "error_type": "æ‹¼å¯«éŒ¯èª¤ / ç”¨å­—é¸æ“‡",
            "problem_description": "å–®å­— 'mutitude' æ‹¼å¯«éŒ¯èª¤ï¼Œæ‡‰ç‚º 'multitude'ã€‚åŒæ™‚ï¼Œ'took place' ç”¨æ–¼æè¿°æŠ˜æ‰£çš„ç™¼ç”Ÿç•¥é¡¯ç”Ÿç¡¬ï¼Œ'were offered' æ›´è‡ªç„¶ã€‚",
            "suggestion": "It was the anniversary of the mall where a multitude of discounts were offered."
            },
            {
            "original_sentence": "Some people waited patiently in line and killed their time by being phubbers, whereas others couldn't stand the taxing process of waiting in line and gave up.",
            "error_type": "ç”¨å­—é¸æ“‡ (éæ­£å¼/ä¿šèª)",
            "problem_description": "'Phubbers' æ˜¯è¼ƒæ–°çš„éæ­£å¼è©å½™ï¼Œä¸ä¸€å®šæ‰€æœ‰è®€è€…éƒ½ç†è§£ï¼Œå»ºè­°åœ¨æ¸¬é©—å¯«ä½œä¸­ä½¿ç”¨æ›´é€šä¿—ã€æ­£å¼çš„è¡¨é”ï¼Œä¾‹å¦‚ 'using their phones' æˆ– 'distracted by their phones'ã€‚'taxing process' è¡¨é”æº–ç¢ºã€‚",
            "suggestion": "Some people waited patiently in line and killed their time by using their phones, whereas others couldn't stand the taxing process of waiting in line and gave up."
            },
            {
            "original_sentence": "To make matters worse, some impatient customers even lost their temper and tried to cut in lines, causing disputes and leaving the mall in chaos.",
            "error_type": "å›ºå®šç”¨æ³•",
            "problem_description": "æ‡‰ç‚º'cut in line'ã€‚",
            "suggestion": "To make matters worse, some impatient customers even lost their temper and tried to cut in line, causing disputes and leaving the mall in chaos."
            },
            {
            "original_sentence": "Others either surrendered or got cut off after the mall closed.",
            "error_type": "ç”¨è©é¸æ“‡",
            "problem_description": "'surrendered'åœ¨æ­¤æƒ…å¢ƒä¸‹ç¨æ­£å¼ï¼Œå¯ç”¨'gave up'ã€‚",
            "suggestion": "Others either gave up or got cut off after the mall closed."
            }
        ],
        "summary_feedback_for_student": 
        {
            "summary_feedback":"ä½ çš„ä½œæ–‡æ•´é«”çµæ§‹å®Œæ•´ï¼Œæ•˜äº‹æµæš¢ï¼Œèƒ½å¤ ç”Ÿå‹•åœ°æå¯«å ´æ™¯å’Œäººç‰©å¿ƒç†ã€‚è©å½™ä½¿ç”¨è±å¯Œï¼Œå±•ç¾äº†ä¸éŒ¯çš„è‹±æ–‡åŸºç¤ã€‚ä¸éï¼Œåœ¨æ‹¼å¯«å’Œç”¨è©çš„æº–ç¢ºæ€§ä¸Šé‚„æœ‰é€²æ­¥ç©ºé–“ã€‚æ³¨æ„æª¢æŸ¥æ‹¼å¯«éŒ¯èª¤ï¼Œä¸¦é¸æ“‡æ›´è²¼åˆ‡ã€è‡ªç„¶çš„è©å½™ï¼Œå¯ä»¥è®“ä½ çš„ä½œæ–‡æ›´ä¸Šä¸€å±¤æ¨“ã€‚",
            "total_score_display": "92 / 100",
            "suggested_grade_display": "A-",
            "grade_basis_display": "æ ¹æ“šåœ‹ä¸­ä¸‰å¹´ç´šå¯«ä½œæ¨™æº–"
        },
        "revised_demonstration": 
        {
            "original_with_errors_highlighted": "<strong>Anxiously</strong> waiting, legions of people stood in front of the gate. It was the anniversary of the mall where a <strong>mutitude</strong> of discounts took place. When it was about eight AM, a <strong>staff</strong> of the mall approached the door. No sooner did he open the door than the crowd dashed in. They entered every store, took what they wanted to <strong>bry</strong>, and <strong>literally</strong> went on a shopping spree. Thousands of purchases were made and everyone thought that they could shop to their hearts' <strong>contert</strong>. However, the story unfolded in the opposite way. As more and more people got into the mall, not only were the stores packed, but the line waiting in front of the cashier stretched for more than ten meters. The smiles on people's face and their <strong>electricfied</strong> mood <strong>withered</strong> as time went by. The time spent on <strong>shoppirg</strong> was actually less than the time spent on waiting. Given this frustrating condition, the crowd had different reactions. Some people waited patiently in line and killed their time by being <strong>phubbers</strong>, whereas others couldn't stand the <strong>taxing</strong> process of waiting in line and gave up. To make matters worse, some impatient customers even lost their temper and tried to cut in lines, causing disputes and leaving the mall in chaos. At the end of the day, only one third of the customers made it to pay for what they had taken. Others either <strong>surrendered</strong> or got cut off after the mall closed. The next day, this incident was reported by the news, and people started to reflect. Eventually, most of them reached the same conclusion that we should no longer blindly follow the crowd and get fooled by the marketing strategies of the mall. After all, no one wants to wait in line for hours and wind up wasting their time.",
            "suggested_revision": "Anxiously waiting, legions of people stood in front of the gate. It was the anniversary of the mall where a large number of discounts were offered. When it was about eight AM, an employee of the mall approached the door. No sooner did he open the door than the crowd dashed in. They entered every store, took what they wanted to buy, and went on a shopping spree. Thousands of purchases were made and everyone thought that they could shop to their hearts' content. However, the story unfolded in the opposite way. As more and more people got into the mall, not only were the stores packed, but the line waiting in front of the cashier stretched for more than ten meters. The smiles on people's faces and their electrified mood faded as time went by. The time spent on shopping was actually less than the time spent on waiting. Given this frustrating condition, the crowd had different reactions. Some people waited patiently in line and killed their time by using their phones, whereas others couldn't stand the difficult process of waiting in line and gave up. To make matters worse, some impatient customers even lost their temper and tried to cut in lines, causing disputes and leaving the mall in chaos. At the end of the day, only one third of the customers made it to pay for what they had taken. Others either gave up or got cut off after the mall closed. The next day, this incident was reported by the news, and people started to reflect. Eventually, most of them reached the same conclusion that we should no longer blindly follow the crowd and get fooled by the marketing strategies of the mall. After all, no one wants to wait in line for hours and wind up wasting their time."
        },
        "positive_learning_feedback": "ä½ çš„å¯«ä½œå±•ç¾äº†å¾ˆå¼·çš„æ•˜äº‹èƒ½åŠ›å’Œè±å¯Œçš„è©å½™é‡ï¼Œèƒ½å¤ æ¸…æ¥šåœ°è¡¨é”æƒ³æ³•ï¼Œè®“è®€è€…æ„Ÿå—åˆ°ä½ çš„æ€è€ƒèˆ‡æƒ…æ„Ÿã€‚å³ä½¿éç¨‹ä¸­å‡ºç¾äº†ä¸€äº›å°éŒ¯èª¤ï¼Œä¹Ÿå®Œå…¨ä¸å½±éŸ¿æ•´é«”çš„è¡¨ç¾ã€‚è«‹ä¸è¦å› æ­¤æ°£é¤’ï¼Œå› ç‚ºæ¯ä¸€æ¬¡å¯«ä½œçš„ç·´ç¿’ï¼Œéƒ½æ˜¯ä¸€æ¬¡é›£èƒ½å¯è²´çš„å­¸ç¿’èˆ‡æˆé•·æ©Ÿæœƒã€‚é€éä¸æ–·åœ°ä¿®æ­£èˆ‡å˜—è©¦ï¼Œä½ æœƒæ›´äº†è§£è‡ªå·±çš„é¢¨æ ¼ï¼Œä¹Ÿæœƒæ¼¸æ¼¸æŒæ¡å¦‚ä½•è®“èªè¨€æ›´å…·æ„ŸæŸ“åŠ›ã€‚ç¹¼çºŒä¿æŒä½ å°å¯«ä½œçš„ç†±æƒ…èˆ‡å¥½å¥‡å¿ƒï¼Œç›¸ä¿¡ä½ æœƒåœ¨é€™æ¢è·¯ä¸Šè¶Šèµ°è¶Šç©©ï¼Œè¶Šå¯«è¶Šå¥½ï¼Œæœªä¾†ä¹Ÿæœ‰æ©Ÿæœƒå‰µä½œå‡ºæ›´å¤šä»¤äººå°è±¡æ·±åˆ»çš„ä½œå“ï¼"
        }
        mock_learning_sheet_structure = {
        "submissionType": "å­¸ç¿’å–®æ‰¹æ”¹",
        "title": "ğŸ“‹ å­¸ç¿’å–®æ‰¹æ”¹çµæœ",
        "sections": [
            {
            "section_title": "[è€ƒå·ä¸Šçš„å¤§æ¨™é¡Œ(ç²—é«”)]",
            "questions_feedback": [
                {
                "question_number": "1",
                "student_answer": "[å­¸ç”Ÿå¯¦éš›çš„ç­”æ¡ˆ]",
                "is_correct": "[âœ…/âŒ]",
                "comment": "[æ ¹æ“šå­¸ç”Ÿç­”æ¡ˆæ­£ç¢ºæˆ–éŒ¯èª¤ç”Ÿæˆå…§å®¹]",
                "correct_answer": "[[æ¨™æº–ç­”æ¡ˆ]ä¸­å°æ‡‰é¡Œè™Ÿçš„æ­£ç¢ºç­”æ¡ˆ]",
                "answer_source_query":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›å‡ºè™•(search_tool(query=''))]",
                "answer_source_content":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›çš„å…§å®¹(æ ¼å¼ç¯„ä¾‹:Lesson 1/Pre-listening Questions/1:Yes, there are two sports teams in my school. They are the soccer team and the basketball team.)]"
                },
                {
                "question_number": "2",
                "student_answer": "[å­¸ç”Ÿå¯¦éš›çš„ç­”æ¡ˆ]",
                "is_correct": "[âœ…/âŒ]",
                "comment": "[æ ¹æ“šå­¸ç”Ÿç­”æ¡ˆæ­£ç¢ºæˆ–éŒ¯èª¤ç”Ÿæˆå…§å®¹]",
                "correct_answer": "[[æ¨™æº–ç­”æ¡ˆ]ä¸­å°æ‡‰é¡Œè™Ÿçš„æ­£ç¢ºç­”æ¡ˆ]",
                "answer_source_query":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›å‡ºè™•(search_tool(query=''))]",
                "answer_source_content":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›çš„å…§å®¹(æ ¼å¼ç¯„ä¾‹:Lesson 1/Pre-listening Questions/2:Yes, I play sports in my free time.)]"
                }
            ],
            "section_summary": "[æ ¹æ“šå­¸ç”Ÿåœ¨æ­¤éƒ¨åˆ†çš„è¡¨ç¾ç”Ÿæˆç¸½çµ]"
            },
            {
            "section_title": "[è€ƒå·ä¸Šçš„å¤§æ¨™é¡Œ(ç²—é«”)]",
            "questions_feedback": [
                {
                "question_number": "1",
                "student_answer": "[å­¸ç”Ÿå¯¦éš›çš„ç­”æ¡ˆ]",
                "is_correct": "[âœ…/âŒ]",
                "comment": "[æ ¹æ“šå­¸ç”Ÿç­”æ¡ˆæ­£ç¢ºæˆ–éŒ¯èª¤ç”Ÿæˆå…§å®¹]",
                "correct_answer": "[[æ¨™æº–ç­”æ¡ˆ]ä¸­å°æ‡‰é¡Œè™Ÿçš„æ­£ç¢ºç­”æ¡ˆ]",
                "answer_source_query":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›å‡ºè™•(search_tool(query=''))]",
                "answer_source_content":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›çš„å…§å®¹(æ ¼å¼ç¯„ä¾‹:Lesson 1/While-listening Notes/1:Do you practice basketball after school every day)]"
                }
            ],
            "section_summary": "[æ ¹æ“šå­¸ç”Ÿåœ¨æ­¤éƒ¨åˆ†çš„è¡¨ç¾ç”Ÿæˆç¸½çµ]"
            },
            {
            "section_title": "[è€ƒå·ä¸Šçš„å¤§æ¨™é¡Œ(ç²—é«”)]",
            "questions_feedback": [
                {
                "question_number": "1",
                "student_answer": "[å­¸ç”Ÿå¯¦éš›çš„ç­”æ¡ˆ]",
                "is_correct": "[âœ…/âŒ]",
                "comment": "[æ ¹æ“šå­¸ç”Ÿç­”æ¡ˆæ­£ç¢ºæˆ–éŒ¯èª¤ç”Ÿæˆå…§å®¹]",
                "correct_answer": "[[æ¨™æº–ç­”æ¡ˆ]ä¸­å°æ‡‰é¡Œè™Ÿçš„æ­£ç¢ºç­”æ¡ˆ]",
                "answer_source_query":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›å‡ºè™•(search_tool(query=''))]",
                "answer_source_content":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›çš„å…§å®¹(æ ¼å¼ç¯„ä¾‹:Lesson 1/Dialogue Mind Map/1:basketball]"
                }
            ],
            "section_summary": "[æ ¹æ“šå­¸ç”Ÿåœ¨æ­¤éƒ¨åˆ†çš„è¡¨ç¾ç”Ÿæˆç¸½çµï¼Œä¸¦ä¾ç…§III.çš„é…åˆ†è¨ˆåˆ†]"
            },
            {
            "section_title": "[è€ƒå·ä¸Šçš„å¤§æ¨™é¡Œ(ç²—é«”)]",
            "questions_feedback": [ 
                {
                "question_number": "1", 
                "student_answer": "[å­¸ç”Ÿå¯¦éš›çš„ç­”æ¡ˆ]",
                "is_correct": "[âœ…/âŒ]", 
                "comment": "[æ ¹æ“šå­¸ç”Ÿç­”æ¡ˆæ­£ç¢ºæˆ–éŒ¯èª¤ç”Ÿæˆå…§å®¹]",
                "correct_answer": "[[æ¨™æº–ç­”æ¡ˆ]ä¸­å°æ‡‰é¡Œè™Ÿçš„æ­£ç¢ºç­”æ¡ˆ]",
                "answer_source_query":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›å‡ºè™•(search_tool(query=''))]",
                "answer_source_content":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›çš„å…§å®¹(æ ¼å¼ç¯„ä¾‹:Lesson 1/Post-listening Questions and Answers/1:They worry about their grades at school.)]"
                }
            ],
            "section_summary": "[æ ¹æ“šå­¸ç”Ÿåœ¨æ­¤éƒ¨åˆ†çš„è¡¨ç¾ç”Ÿæˆç¸½çµ]"
            }
        ],
        "overall_score_summary_title": "âœ… ç¸½åˆ†çµ±è¨ˆèˆ‡ç­‰ç¬¬å»ºè­°",
        "score_breakdown_table": [
            {
            "section": "[è€ƒå·ä¸Šçš„å¤§æ¨™é¡Œ(ç²—é«”)]",
            "max_score": "[æ ¹æ“šè€ƒå·ä¸Šçš„é…åˆ†]",
            "obtained_score": "[è¨ˆç®—æ­¤éƒ¨åˆ†å¾—åˆ†]"
            },
            {
            "section": "[è€ƒå·ä¸Šçš„å¤§æ¨™é¡Œ(ç²—é«”)]",
            "max_score": "[æ ¹æ“šè€ƒå·ä¸Šçš„é…åˆ†]",
            "obtained_score": "[è¨ˆç®—æ­¤éƒ¨åˆ†å¾—åˆ†]"
            },
            {
            "section": "[è€ƒå·ä¸Šçš„å¤§æ¨™é¡Œ(ç²—é«”)]",
            "max_score": "[æ ¹æ“šè€ƒå·ä¸Šçš„é…åˆ†]",
            "obtained_score": "[è¨ˆç®—æ­¤éƒ¨åˆ†å¾—åˆ†]"
            },
            {
            "section": "[è€ƒå·ä¸Šçš„å¤§æ¨™é¡Œ(ç²—é«”)]",
            "max_score": "[æ ¹æ“šè€ƒå·ä¸Šçš„é…åˆ†]",
            "obtained_score": "[è¨ˆç®—æ­¤éƒ¨åˆ†å¾—åˆ†]"
            }
        ],
        "final_total_score_text": "ç¸½åˆ†ï¼š100 å­¸ç”Ÿåˆ†æ•¸ï¼š[å­¸ç”Ÿå¾—åˆ†]",
        "final_suggested_grade_title": "ğŸ”ºç­‰ç¬¬å»ºè­°",
        "final_suggested_grade_text": "[æ ¹æ“šç¸½åˆ†ç”Ÿæˆå»ºè­°ç­‰ç¬¬èˆ‡èªªæ˜]",
        "overall_feedback_title": "ğŸ“š ç¸½çµæ€§å›é¥‹å»ºè­°ï¼ˆå¯è¤‡è£½çµ¦å­¸ç”Ÿï¼‰",
        "overall_feedback": "[é‡å°å­¸ç”Ÿè€ƒå·çš„ä½œç­”æ•´é«”è¡¨ç¾ç”Ÿæˆæ­£é¢ç¸½çµæ€§å›é¥‹]"
        }

        # æ–°å¢ï¼šè®€å¯«ç¿’ä½œè©•åˆ†çš„ JSON çµæ§‹ç¯„ä¾‹
        mock_reading_writing_structure = {
        "submissionType": "è®€å¯«ç¿’ä½œè©•åˆ†",
        "title": "ğŸ“˜è®€å¯«ç¿’ä½œæ‰¹æ”¹çµæœ",
        "sections": [
            {
            "section_title": "I. [è€ƒå·ä¸Šçš„å¤§æ¨™é¡Œèˆ‡é…åˆ†]",
            "questions_feedback": [
                {
                "question_number": "1",
                "student_answer": "[å­¸ç”Ÿå¯¦éš›çš„ç­”æ¡ˆ]",
                "is_correct": "[âœ…/âŒ]",
                "comment": "[æ ¹æ“šå­¸ç”Ÿç­”æ¡ˆæ­£ç¢ºæˆ–éŒ¯èª¤ç”Ÿæˆå…§å®¹]",
                "correct_answer": "[[å­¸ç”Ÿå¹´ç´š]ç¿’ä½œæ¨™æº–ç­”æ¡ˆ]",
                "answer_source_query":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›å‡ºè™•(search_tool(query=''))]",
                "answer_source_content":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›çš„å…§å®¹(æ ¼å¼ç¯„ä¾‹:Book 5/Lesson 2/I Read and Write/1:interests)]"
                },
                {
                "question_number": "2",
                "student_answer": "[å­¸ç”Ÿå¯¦éš›çš„ç­”æ¡ˆ]",
                "is_correct": "[âœ…/âŒ]",
                "comment": "[æ ¹æ“šå­¸ç”Ÿç­”æ¡ˆæ­£ç¢ºæˆ–éŒ¯èª¤ç”Ÿæˆå…§å®¹]",
                "correct_answer": "[[å­¸ç”Ÿå¹´ç´š]ç¿’ä½œæ¨™æº–ç­”æ¡ˆ]",
                "answer_source_query":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›å‡ºè™•(search_tool(query=''))]",
                "answer_source_content":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›çš„å…§å®¹(æ ¼å¼ç¯„ä¾‹:Book 5/Lesson 2/I Read and Write/2:reason)]"
                }
            ],
            "section_summary": "[æ ¹æ“šå­¸ç”Ÿåœ¨æ­¤éƒ¨åˆ†çš„è¡¨ç¾ç”Ÿæˆç¸½çµï¼Œä¸¦ä¾ç…§I.çš„é…åˆ†è¨ˆåˆ†]"
            },
            {
            "section_title": "II. [è€ƒå·ä¸Šçš„å¤§æ¨™é¡Œèˆ‡é…åˆ†]",
            "questions_feedback": [
                {
                "question_number": "1",
                "student_answer": "[å­¸ç”Ÿå¯¦éš›çš„ç­”æ¡ˆ]",
                "is_correct": "[âœ…/âŒ]",
                "comment": "[æ ¹æ“šå­¸ç”Ÿç­”æ¡ˆæ­£ç¢ºæˆ–éŒ¯èª¤ç”Ÿæˆå…§å®¹]",
                "correct_answer": "[[å­¸ç”Ÿå¹´ç´š]ç¿’ä½œæ¨™æº–ç­”æ¡ˆ]",
                "answer_source_query":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›å‡ºè™•(search_tool(query=''))]",
                "answer_source_content":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›çš„å…§å®¹(æ ¼å¼ç¯„ä¾‹:Book 5/Lesson 2/II Look and Fill In/1:tiring)]"
                }
            ],
            "section_summary": "[æ ¹æ“šå­¸ç”Ÿåœ¨æ­¤éƒ¨åˆ†çš„è¡¨ç¾ç”Ÿæˆç¸½çµï¼Œä¸¦ä¾ç…§II.çš„é…åˆ†è¨ˆåˆ†]"
            },
            {
            "section_title": "III. [è€ƒå·ä¸Šçš„å¤§æ¨™é¡Œèˆ‡é…åˆ†]",
            "questions_feedback": [
                {
                "question_number": "1",
                "student_answer": "[å­¸ç”Ÿå¯¦éš›çš„ç­”æ¡ˆ]",
                "is_correct": "[âœ…/âŒ]",
                "comment": "[æ ¹æ“šå­¸ç”Ÿç­”æ¡ˆæ­£ç¢ºæˆ–éŒ¯èª¤ç”Ÿæˆå…§å®¹]",
                "correct_answer": "[[å­¸ç”Ÿå¹´ç´š]ç¿’ä½œæ¨™æº–ç­”æ¡ˆ]",
                "answer_source_query":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›å‡ºè™•(search_tool(query=''))]",
                "answer_source_content":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›çš„å…§å®¹(æ ¼å¼ç¯„ä¾‹:Book 5/Lesson 2/III Read and Write/1:James thought (that) Linda would like the gift.]"
                }
            ],
            "section_summary": "[æ ¹æ“šå­¸ç”Ÿåœ¨æ­¤éƒ¨åˆ†çš„è¡¨ç¾ç”Ÿæˆç¸½çµï¼Œä¸¦ä¾ç…§III.çš„é…åˆ†è¨ˆåˆ†]"
            },
            {
            "section_title": "IV.[è€ƒå·ä¸Šçš„å¤§æ¨™é¡Œèˆ‡é…åˆ†]",
            "questions_feedback": [ 
                {
                "question_number": "1", 
                "student_answer": "[å­¸ç”Ÿå¯¦éš›çš„ç­”æ¡ˆ]",
                "is_correct": "[âœ…/âŒ]", 
                "comment": "[æ ¹æ“šå­¸ç”Ÿç­”æ¡ˆæ­£ç¢ºæˆ–éŒ¯èª¤ç”Ÿæˆå…§å®¹]",
                "correct_answer": "[[å­¸ç”Ÿå¹´ç´š]ç¿’ä½œæ¨™æº–ç­”æ¡ˆ]",
                "answer_source_query":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›å‡ºè™•(search_tool(query=''))]",
                "answer_source_content":"[æ¨™æº–ç­”æ¡ˆå¯¦éš›çš„å…§å®¹(æ ¼å¼ç¯„ä¾‹:Book 5/Lesson 2/IV Fill In/1:reasons / choice)]"
                }
            ],
            "section_summary": "[æ ¹æ“šå­¸ç”Ÿåœ¨æ­¤éƒ¨åˆ†çš„è¡¨ç¾ç”Ÿæˆç¸½çµï¼Œä¸¦ä¾ç…§IV.çš„é…åˆ†è¨ˆåˆ†]"
            }
        ],
        "overall_score_summary_title": "âœ… ç¸½åˆ†çµ±è¨ˆèˆ‡ç­‰ç¬¬å»ºè­°",
        "score_breakdown_table": [
            {
            "section": "I. Vocabulary & Grammar",
            "max_score": "[æ ¹æ“šè€ƒå·ä¸Šçš„é…åˆ†]",
            "obtained_score": "[è¨ˆç®—æ­¤éƒ¨åˆ†å¾—åˆ†]"
            },
            {
            "section": "II. Cloze Test",
            "max_score": "[æ ¹æ“šè€ƒå·ä¸Šçš„é…åˆ†]",
            "obtained_score": "[è¨ˆç®—æ­¤éƒ¨åˆ†å¾—åˆ†]"
            },
            {
            "section": "III. Reading Comprehension",
            "max_score": "[æ ¹æ“šè€ƒå·ä¸Šçš„é…åˆ†]",
            "obtained_score": "[è¨ˆç®—æ­¤éƒ¨åˆ†å¾—åˆ†]"
            },
            {
            "section": "IV. Write",
            "max_score": "[æ ¹æ“šè€ƒå·ä¸Šçš„é…åˆ†]",
            "obtained_score": "[è¨ˆç®—æ­¤éƒ¨åˆ†å¾—åˆ†]"
            }
        ],
        "final_total_score_text": "ç¸½åˆ†ï¼š100 å­¸ç”Ÿåˆ†æ•¸ï¼š[å­¸ç”Ÿå¾—åˆ†]",
        "final_suggested_grade_title": "ğŸ”ºç­‰ç¬¬å»ºè­°",
        "final_suggested_grade_text": "[æ ¹æ“šç¸½åˆ†ç”Ÿæˆå»ºè­°ç­‰ç¬¬èˆ‡èªªæ˜]",
        "overall_feedback_title": "ğŸ“š ç¸½çµæ€§å›é¥‹å»ºè­°ï¼ˆå¯è¤‡è£½çµ¦å­¸ç”Ÿï¼‰",
        "overall_feedback": "[é‡å°å­¸ç”Ÿè€ƒå·çš„ä½œç­”æ•´é«”è¡¨ç¾ç”Ÿæˆæ­£é¢ç¸½çµæ€§å›é¥‹]"
        }
        json_format_example_str = get_json_format_example(
            submission_type,
            mock_paragraph_data_for_structure,
            mock_quiz_data_for_structure,
            mock_learning_sheet_structure,
            mock_reading_writing_structure
        )

        # --- 4. å¡«å…… Prompt æ¨¡æ¿ ---
        # å‡è¨­æ‚¨çš„ GCS Prompt æ–‡ä»¶ä½¿ç”¨ Python çš„ .format() é¢¨æ ¼ä½”ä½ç¬¦
        # ä¾‹å¦‚ï¼š "å­¸ç”Ÿå¹´ç´šï¼š{grade_level}\nä½œæ–‡å…§å®¹ï¼š\n{essay_content}\nJSONç¯„ä¾‹ï¼š\n{json_example}"
        try:
            final_prompt = base_prompt_text.format(
                Book = bookrange if submission_type == 'è®€å¯«ç¿’ä½œè©•åˆ†' else "",
                learnsheet = learnsheets if submission_type == 'å­¸ç¿’å–®æ‰¹æ”¹' else "",
                grade_level=grade_level,
                submission_type=submission_type,
                essay_content=essay_content,
                standard_answer_if_any=processed_standard_answer if submission_type == 'æ¸¬é©—å¯«ä½œè©•æ”¹' else "",
                scoring_instructions_if_any=scoring_instructions if submission_type == 'æ¸¬é©—å¯«ä½œè©•æ”¹' else "",
                json_format_example_str=json_format_example_str,
                current_lesson_standard_answers_json=standard_answers_json_str
            )
        except KeyError as ke:
            print(f"Error formatting prompt: Missing key {ke} in prompt template or provided variables.")
            return jsonify({"error": f"Prompt template formatting error: Missing key {ke}"}), 500

        print(f"Final prompt (first 300 chars, excluding JSON example): {final_prompt.split('JSON è¼¸å‡ºæ ¼å¼ç¯„ä¾‹ï¼š')}...")

        # å°‡ final_prompt å­—ç¬¦ä¸²ä½œç‚ºç¬¬ä¸€å€‹æ–‡æœ¬ Part åŠ å…¥åˆ° contents_for_gemini åˆ—è¡¨çš„é–‹é ­
        contents_for_gemini.insert(0, Part.from_text(final_prompt))

        print(f"Total parts to send to Gemini: {len(contents_for_gemini)}")

        # --- 5. èª¿ç”¨ Gemini æ¨¡å‹ ---
        generation_config = {
            "temperature": 0.1,
            "top_p": 0.5,
            "max_output_tokens": 8192,
            "response_mime_type": "application/json",
        }

        # è¨­ç½®å®‰å…¨è¨­å®šï¼Œé¿å…å› å®‰å…¨å•é¡Œè¢«é˜»æ“‹
        safety_settings = {
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        }

        # åœ¨å‘¼å« gemini_model.generate_content(...) ä¹‹å‰
        print(f"DEBUG: Size of final_prompt in memory: {get_size(final_prompt):.2f} MB")
        print(f"DEBUG: Size of contents_for_gemini list in memory: {get_size(contents_for_gemini):.2f} MB")

        print("Calling Gemini model with non-streaming mode...")
        
        # ã€ä¿®æ”¹é» 1ã€‘å°‡å‘¼å« Gemini çš„ç¨‹å¼ç¢¼åŒ…åœ¨ try-except ä¸­ï¼Œä»¥æ•ç² API å¯èƒ½çš„éŒ¯èª¤
        try:
            response = gemini_model.generate_content(
                contents_for_gemini,
                generation_config=generation_config,
                tools=tools_list,
                safety_settings=safety_settings  # ã€æ–°å¢ã€‘åŠ å…¥å®‰å…¨è¨­å®š
            )
            print("Gemini model responded.")
        except Exception as api_error:
            print(f"Error calling Gemini API: {api_error}")
            traceback.print_exc()
            # å˜—è©¦æ‰“å° response çš„éƒ¨åˆ†å…§å®¹ä»¥ä¾›é™¤éŒ¯
            error_details = str(api_error)
            return jsonify({"error": "AI model API call failed.", "details_for_log": error_details}), 500


        try:
            # æ­¥é©Ÿ 1: æª¢æŸ¥æ˜¯å¦æœ‰å€™é¸ç­”æ¡ˆ
            if not response.candidates:
                finish_reason = getattr(response, 'prompt_feedback', 'No prompt_feedback attribute')
                if hasattr(finish_reason, 'block_reason'):
                    finish_reason = f"Blocked due to: {finish_reason.block_reason}"
                print(f"Error: Gemini response is empty or blocked. Finish reason: {finish_reason}")
                return jsonify({"error": "AI model did not return a valid response (it might have been blocked).", "details_for_log": str(finish_reason)}), 500

            # æ­¥é©Ÿ 2: æ‰‹å‹•æ‹¼æ¥æ‰€æœ‰ text parts
            # é€™æ˜¯è§£æ±º "Multiple content parts are not supported" çš„é—œéµ
            full_response_text = "".join(part.text for part in response.candidates[0].content.parts if hasattr(part, 'text'))
            
            print(f"Combined raw AI response text (first 300 chars): {full_response_text[:300]}...")

            # æ­¥é©Ÿ 3: å¾æ‹¼æ¥å¾Œçš„å®Œæ•´å­—ä¸²ä¸­æå– JSON å€å¡Š
            # é€™å€‹é‚è¼¯å¯ä»¥è™•ç† JSON å‰å¾Œæœ‰å…¶ä»–æ–‡å­—çš„æƒ…æ³
            json_block_match = re.search(r"```json\s*(\{.*?\})\s*```", full_response_text, re.DOTALL)
            
            if json_block_match:
                ai_response_text = json_block_match.group(1)
                print("Successfully extracted JSON block using regex.")
            else:
                # å¦‚æœæ­£å‰‡è¡¨é”å¼æ‰¾ä¸åˆ°ï¼Œä½œç‚ºå‚™ç”¨æ–¹æ¡ˆï¼Œæˆ‘å€‘å‡è¨­æ•´å€‹æ–‡æœ¬å°±æ˜¯ JSON
                # é€™å¯ä»¥è™•ç†æ¨¡å‹ç›´æ¥è¿”å›ç´” JSON çš„æƒ…æ³
                print("Warning: Could not find ```json``` block. Attempting to parse the whole text.")
                ai_response_text = full_response_text

            # æ­¥é©Ÿ 4: è§£ææå–å‡ºçš„ JSON å­—ä¸²
            ai_result = json.loads(ai_response_text)

            # å¯é¸çš„å¥å…¨æ€§æª¢æŸ¥
            if 'submissionType' not in ai_result or ai_result.get('submissionType') != submission_type:
                print(f"Warning: AI returned submissionType ('{ai_result.get('submissionType')}') differs from request ('{submission_type}'). Correcting.")
                ai_result['submissionType'] = submission_type
            
            print("Successfully parsed AI JSON response.")
            return jsonify(ai_result)

        except json.JSONDecodeError as je:
            print(f"AI response JSON decode error: {je}")
            # ç•¶è§£æå¤±æ•—æ™‚ï¼Œæ‰“å°æ‹¼æ¥å¾Œçš„å®Œæ•´æ–‡æœ¬ï¼Œè€Œä¸æ˜¯å¯èƒ½ä¸å®Œæ•´çš„ ai_response_text
            print(f"Problematic AI response text: {full_response_text}")
            return jsonify({"error": "AI response format error (cannot parse JSON).", "details_for_log": full_response_text[:500]}), 500
        
        except Exception as e:
            print(f"Error processing Gemini response: {e}")
            traceback.print_exc()
            error_detail = str(response) if len(str(response)) < 500 else str(response)[:500] + "..."
            return jsonify({"error": "Failed to process AI response.", "details_for_log": error_detail}), 500

    except Exception as e:
        print(f"Overall error in /api/grade: {e}")
        traceback.print_exc()
        return jsonify({"error": "Internal server error during grading.", "details": str(e)}), 500
# --- æ‡‰ç”¨ç¨‹å¼å•Ÿå‹• ---
if __name__ == '__main__':
    # å¾ç’°å¢ƒè®Šæ•¸ç²å– PORTï¼Œå…è¨± Cloud Run ç­‰å¹³å°è¨­ç½®
    port = int(os.environ.get("PORT", 5000))
    # ç”Ÿç”¢ç’°å¢ƒä¸­ debug æ‡‰ç‚º False
    app.run(host='0.0.0.0', port=port, debug=os.environ.get("FLASK_DEBUG", "True").lower() == "true")
